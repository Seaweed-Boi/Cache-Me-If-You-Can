version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6380:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6334:6333"
    volumes:
      - qdrant_storage:/qdrant/storage
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:6333/collections || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 10s

  mock_llm:
    build:
      context: ./services/mock_llm
      dockerfile: Dockerfile
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - API_PORT=8000
    ports:
      - "8888:8000"
    depends_on:
      - redis

  llm_generator_1:
    build:
      context: ./services/llm_generator
      dockerfile: Dockerfile
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OLLAMA_URL=http://mock_llm:8000/generate
      - WORKER_NAME=llm_generator_1
    depends_on:
      - redis
      - mock_llm
    restart: unless-stopped

  llm_generator_2:
    build:
      context: ./services/llm_generator
      dockerfile: Dockerfile
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OLLAMA_URL=http://mock_llm:8000/generate
      - WORKER_NAME=llm_generator_2
    depends_on:
      - redis
      - mock_llm
    restart: unless-stopped

  llm_generator_3:
    build:
      context: ./services/llm_generator
      dockerfile: Dockerfile
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OLLAMA_URL=http://mock_llm:8000/generate
      - WORKER_NAME=llm_generator_3
    depends_on:
      - redis
      - mock_llm
    restart: unless-stopped

  api_gateway:
    build:
      context: ./services/api_gateway
      dockerfile: Dockerfile
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - API_PORT=8000
      - RL_AGENT_URL=http://rl_agent:5000
      - USE_RL_AGENT=true
    ports:
      - "8001:8000"
    depends_on:
      - redis
    restart: unless-stopped

  encoder_service:
    build:
      context: ./services/encoder_service
      dockerfile: Dockerfile
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - EMBEDDING_MODEL=all-MiniLM-L6-v2
      - EMBEDDING_DEVICE=cpu
    depends_on:
      - redis
      - qdrant
    restart: unless-stopped

  retriever_service:
    build:
      context: ./services/retriever_service
      dockerfile: Dockerfile
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
    depends_on:
      - redis
      - qdrant
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./rag-optimizer/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9091:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    restart: unless-stopped

  rl_agent:
    build:
      context: ./services/rl_agent
      dockerfile: Dockerfile
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PROMETHEUS_URL=http://prometheus:9090
      - MODEL_PATH=/models/rl_agent.pth
      - NUM_REPLICAS=2
      - RL_EXPLORATION=true
    ports:
      - "5001:5000"
    volumes:
      - rl_models:/models
    depends_on:
      - redis
      - prometheus
    restart: unless-stopped

volumes:
  qdrant_storage:
  rl_models:
